
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<div class="notebook">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Optimize-acquisition-functions-using-CMA-ES">Optimize acquisition functions using CMA-ES<a class="anchor-link" href="#Optimize-acquisition-functions-using-CMA-ES">¶</a></h2><p>In this tutorial, we show how to use an external optimizer (in this case <a href="https://en.wikipedia.org/wiki/CMA-ES">CMA-ES</a>) for optimizing BoTorch acquisition functions. CMA-ES is a zero-th order optimizer, meaning that it only uses function evaluations and does not require gradient information. This is of course very useful if gradient information about the function to be optimized is unavailable.</p>
<p>In BoTorch, we typically do have gradient information available (thanks, autograd!). One is also generally better off using this information, rather than just ignoring it. However, for certain custom models or acquisition functions, we may not be able to backprop through the acquisition function and/or model. In such instances, using a zero-th order optimizer is appropriate.</p>
<p>For this example we use the <a href="https://github.com/CMA-ES/pycma">PyCMA</a> implementation of CMA-ES. PyCMA is easily installed via pip by running <code>pip install cma</code>.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Setting-up-the-acquisition-function">Setting up the acquisition function<a class="anchor-link" href="#Setting-up-the-acquisition-function">¶</a></h3><p>For the purpose of this tutorial, we'll use a basic <code>UpperConfidenceBound</code> acquisition function on a basic model fit on synthetic data. Please see the documentation for <a href="../docs/models">Models</a> and <a href="../docs/acquisition">Acquisition Functions</a> for more information.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [4]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">botorch.fit</span> <span class="kn">import</span> <span class="n">fit_gpytorch_mll</span>
<span class="kn">from</span> <span class="nn">botorch.models</span> <span class="kn">import</span> <span class="n">SingleTaskGP</span>
<span class="kn">from</span> <span class="nn">gpytorch.mlls</span> <span class="kn">import</span> <span class="n">ExactMarginalLogLikelihood</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span>
<span class="n">Y</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">+=</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>

<span class="n">gp</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">mll</span> <span class="o">=</span> <span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">gp</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">gp</span><span class="p">)</span>
<span class="n">fit_gpytorch_mll</span><span class="p">(</span><span class="n">mll</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [5]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">botorch.acquisition</span> <span class="kn">import</span> <span class="n">UpperConfidenceBound</span>

<span class="n">UCB</span> <span class="o">=</span> <span class="n">UpperConfidenceBound</span><span class="p">(</span><span class="n">gp</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Optimizing-the-acquisition-function-using-CMA-ES">Optimizing the acquisition function using CMA-ES<a class="anchor-link" href="#Optimizing-the-acquisition-function-using-CMA-ES">¶</a></h3><p><strong>Note:</strong> Relative to sequential evaluations, parallel evaluations of the acqusition function are extremely fast in botorch (due to automatic parallelization across batch dimensions). In order to exploit this, we use the "ask/tell" interface to <code>cma</code> - this way we can batch-evaluate the whole CMA-ES population in parallel.</p>
<p>In this examle we use an initial standard deviation $\sigma_0 = 0.2$ and a population size $\lambda = 50$.
We also constrain the input <code>X</code> to the unit cube $[0, 1]^d$.
See <code>cma</code>'s <a href="http://cma.gforge.inria.fr/apidocs-pycma/cma.evolution_strategy.CMAEvolutionStrategy.html">API Reference</a> for more information on these options.</p>
<p>With this, we can optimize this acquistition function as follows:</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [6]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">cma</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># get initial condition for CMAES in numpy form</span>
<span class="c1"># note that CMAES expects a different shape (no explicit q-batch dimension)</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># create the CMA-ES optimizer</span>
<span class="n">es</span> <span class="o">=</span> <span class="n">cma</span><span class="o">.</span><span class="n">CMAEvolutionStrategy</span><span class="p">(</span>
    <span class="n">x0</span><span class="o">=</span><span class="n">x0</span><span class="p">,</span>
    <span class="n">sigma0</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">inopts</span><span class="o">=</span><span class="p">{</span><span class="s2">"bounds"</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s2">"popsize"</span><span class="p">:</span> <span class="mi">50</span><span class="p">},</span>
<span class="p">)</span>

<span class="c1"># speed up things by telling pytorch not to generate a compute graph in the background</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>

    <span class="c1"># Run the optimization loop using the ask/tell interface -- this uses</span>
    <span class="c1"># PyCMA's default settings, see the PyCMA documentation for how to modify these</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="n">es</span><span class="o">.</span><span class="n">stop</span><span class="p">():</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="n">es</span><span class="o">.</span><span class="n">ask</span><span class="p">()</span>  <span class="c1"># as for new points to evaluate</span>
        <span class="c1"># convert to Tensor for evaluating the acquisition function</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="c1"># evaluate the acquisition function (optimizer assumes we're minimizing)</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="o">-</span><span class="n">UCB</span><span class="p">(</span>
            <span class="n">X</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span>  <span class="c1"># acquisition functions require an explicit q-batch dimension</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">double</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># convert result to numpy array</span>
        <span class="n">es</span><span class="o">.</span><span class="n">tell</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># return the result to the optimizer</span>

<span class="c1"># convert result back to a torch tensor</span>
<span class="n">best_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">es</span><span class="o">.</span><span class="n">best</span><span class="o">.</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">best_x</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>(25_w,50)-aCMA-ES (mu_w=14.0,w_1=14%) in dimension 2 (seed=374178, Thu Aug  8 09:33:08 2019)
</pre>
</div>
</div>
<div class="output_area">
<div class="prompt output_prompt">Out[6]:</div>
<div class="output_text output_subarea output_execute_result">
<pre>tensor([0.2642, 0.0255])</pre>
</div>
</div>
</div>
</div>
</div>
</div>