"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[8006],{5127:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>f,frontMatter:()=>r,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"multi_objective","title":"Multi-Objective Bayesian Optimization","description":"BoTorch provides first-class support for Multi-Objective (MO) Bayesian","source":"@site/versioned_docs/version-v0.13.0/multi_objective.md","sourceDirName":".","slug":"/multi_objective","permalink":"/botorch/docs/multi_objective","draft":false,"unlisted":false,"editUrl":"https://github.com/pytorch/botorch/edit/main/docs/versioned_docs/version-v0.13.0/multi_objective.md","tags":[],"version":"v0.13.0","lastUpdatedBy":"Cristian Lara","lastUpdatedAt":1734368612000,"frontMatter":{"id":"multi_objective","title":"Multi-Objective Bayesian Optimization"},"sidebar":"docs","previous":{"title":"Monte Carlo Samplers","permalink":"/botorch/docs/samplers"}}');var o=n(4848),a=n(8453);const r={id:"multi_objective",title:"Multi-Objective Bayesian Optimization"},s=void 0,c={},l=[{value:"Multi-Objective Acquisition Functions",id:"multi-objective-acquisition-functions",level:2},{value:"Multi-Objective Utilities",id:"multi-objective-utilities",level:2}];function d(e){const t={a:"a",code:"code",em:"em",h2:"h2",li:"li",ol:"ol",p:"p",section:"section",sup:"sup",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)(t.p,{children:["BoTorch provides first-class support for Multi-Objective (MO) Bayesian\nOptimization (BO) including implementations of\n",(0,o.jsx)(t.a,{href:"../api/acquisition.html#botorch.acquisition.multi_objective.logei.qLogNoisyExpectedHypervolumeImprovement",children:(0,o.jsx)(t.code,{children:"qLogNoisyExpectedHypervolumeImprovement"})}),"\n(qLogNEHVI)",(0,o.jsx)(t.sup,{children:(0,o.jsx)(t.a,{href:"#user-content-fn-qnehvi",id:"user-content-fnref-qnehvi","data-footnote-ref":"","aria-describedby":"footnote-label",children:"1"})}),(0,o.jsx)(t.sup,{children:(0,o.jsx)(t.a,{href:"#user-content-fn-logei",id:"user-content-fnref-logei","data-footnote-ref":"","aria-describedby":"footnote-label",children:"2"})}),",\n",(0,o.jsx)(t.a,{href:"../api/acquisition.html#botorch.acquisition.multi_objective.logei.qLogExpectedHypervolumeImprovement",children:(0,o.jsx)(t.code,{children:"qLogExpectedHypervolumeImprovement"})}),"\n(qLogEHVI),\n",(0,o.jsx)(t.a,{href:"../api/acquisition.html#botorch.acquisition.multi_objective.parego.qLogNParEGO",children:(0,o.jsx)(t.code,{children:"qLogNParEGO"})}),(0,o.jsx)(t.sup,{children:(0,o.jsx)(t.a,{href:"#user-content-fn-qnehvi",id:"user-content-fnref-qnehvi-2","data-footnote-ref":"","aria-describedby":"footnote-label",children:"1"})}),",\nand analytic\n",(0,o.jsx)(t.a,{href:"../api/acquisition.html#botorch.acquisition.multi_objective.analytic.ExpectedHypervolumeImprovement",children:(0,o.jsx)(t.code,{children:"ExpectedHypervolumeImprovement"})}),"\n(EHVI) with gradients via auto-differentiation acquisition functions",(0,o.jsx)(t.sup,{children:(0,o.jsx)(t.a,{href:"#user-content-fn-qehvi",id:"user-content-fnref-qehvi","data-footnote-ref":"","aria-describedby":"footnote-label",children:"3"})}),"."]}),"\n",(0,o.jsxs)(t.p,{children:["The goal in MOBO is learn the ",(0,o.jsx)(t.em,{children:"Pareto front"}),": the set of optimal trade-offs,\nwhere an improvement in one objective means deteriorating another objective.\nBotorch provides implementations for a number of acquisition functions\nspecifically for the multi-objective scenario, as well as generic interfaces for\nimplemented new multi-objective acquisition functions."]}),"\n",(0,o.jsx)(t.h2,{id:"multi-objective-acquisition-functions",children:"Multi-Objective Acquisition Functions"}),"\n",(0,o.jsxs)(t.p,{children:["MOBO leverages many advantages of BoTorch to make provide practical algorithms\nfor computationally intensive and analytically intractable problems. For\nexample, analytic EHVI has no known analytical gradient for when there are more\nthan two objectives, but BoTorch computes analytic gradients for free via\nauto-differentiation, regardless of the number of objectives ",(0,o.jsx)(t.sup,{children:(0,o.jsx)(t.a,{href:"#user-content-fn-qehvi",id:"user-content-fnref-qehvi-2","data-footnote-ref":"","aria-describedby":"footnote-label",children:"3"})}),"."]}),"\n",(0,o.jsxs)(t.p,{children:["For analytic and MC-based MOBO acquisition functions such as qLogNEHVI,\nqLogEHVI, and ",(0,o.jsx)(t.code,{children:"qLogNParEGO"}),", BoTorch leverages GPU acceleration and quasi-second\norder methods for acquisition optimization for efficient computation and\noptimization in many practical scenarios ",(0,o.jsx)(t.sup,{children:(0,o.jsx)(t.a,{href:"#user-content-fn-qnehvi",id:"user-content-fnref-qnehvi-3","data-footnote-ref":"","aria-describedby":"footnote-label",children:"1"})}),(0,o.jsx)(t.sup,{children:(0,o.jsx)(t.a,{href:"#user-content-fn-qehvi",id:"user-content-fnref-qehvi-3","data-footnote-ref":"","aria-describedby":"footnote-label",children:"3"})}),". The MC-based\nacquisition functions support using the sample average approximation for rapid\nconvergence ",(0,o.jsx)(t.sup,{children:(0,o.jsx)(t.a,{href:"#user-content-fn-botorch",id:"user-content-fnref-botorch","data-footnote-ref":"","aria-describedby":"footnote-label",children:"4"})}),"."]}),"\n",(0,o.jsxs)(t.p,{children:["All analytic MO acquisition functions derive from\n",(0,o.jsx)(t.a,{href:"../api/acquisition.html#botorch.acquisition.multi_objective.base.MultiObjectiveAnalyticAcquisitionFunction",children:(0,o.jsx)(t.code,{children:"MultiObjectiveAnalyticAcquisitionFunction"})}),"\nand all MC-based acquisition functions derive from\n",(0,o.jsx)(t.a,{href:"../api/acquisition.html#botorch.acquisition.multi_objective.base.MultiObjectiveMCAcquisitionFunction",children:(0,o.jsx)(t.code,{children:"MultiObjectiveMCAcquisitionFunction"})}),".\nThese abstract classes easily integrate with BoTorch's standard optimization\nmachinery."]}),"\n",(0,o.jsxs)(t.p,{children:[(0,o.jsx)(t.code,{children:"qLogNParEGO"})," supports optimization via random scalarizations. In the batch\nsetting, it uses a new random scalarization for each candidate ",(0,o.jsx)(t.sup,{children:(0,o.jsx)(t.a,{href:"#user-content-fn-qehvi",id:"user-content-fnref-qehvi-4","data-footnote-ref":"","aria-describedby":"footnote-label",children:"3"})}),".\nCandidates are selected in a sequential greedy fashion, each with a different\nscalarization, via the\n",(0,o.jsx)(t.a,{href:"../api/optim.html#botorch.optim.optimize.optimize_acqf_list",children:(0,o.jsx)(t.code,{children:"optimize_acqf_list"})}),"\nfunction."]}),"\n",(0,o.jsxs)(t.p,{children:["For a more in-depth example using these acquisition functions, check out the\n",(0,o.jsx)(t.a,{href:"../tutorials/multi_objective_bo",children:"Multi-Objective Bayesian Optimization tutorial notebook"}),"."]}),"\n",(0,o.jsx)(t.h2,{id:"multi-objective-utilities",children:"Multi-Objective Utilities"}),"\n",(0,o.jsxs)(t.p,{children:["BoTorch provides several utility functions for evaluating performance in MOBO\nincluding a method for computing the Pareto front\n",(0,o.jsx)(t.a,{href:"../api/utils.html#botorch.utils.multi_objective.pareto.is_non_dominated",children:(0,o.jsx)(t.code,{children:"is_non_dominated"})}),"\nand efficient box decomposition algorithms for efficiently partitioning the the\nspace dominated\n",(0,o.jsx)(t.a,{href:"../api/utils.html#botorch.utils.multi_objective.box_decompositions.dominated.DominatedPartitioning",children:(0,o.jsx)(t.code,{children:"DominatedPartitioning"})}),"\nor non-dominated\n",(0,o.jsx)(t.a,{href:"../api/utils.html#botorch.utils.multi_objective.box_decompositions.non_dominated.NondominatedPartitioning",children:(0,o.jsx)(t.code,{children:"NonDominatedPartitioning"})}),"\nby the Pareto frontier into axis-aligned hyperrectangular boxes. For exact box\ndecompositions, BoTorch uses a two-step approach similar to that in ",(0,o.jsx)(t.sup,{children:(0,o.jsx)(t.a,{href:"#user-content-fn-yang2019",id:"user-content-fnref-yang2019","data-footnote-ref":"","aria-describedby":"footnote-label",children:"5"})}),",\nwhere (1) Algorithm 1 from [Lacour17]_ is used to find the local lower bounds\nfor the maximization problem and (2) the local lower bounds are used as the\nPareto frontier for the minimization problem, and [Lacour17]_ is applied again\nto partition the space dominated by that Pareto frontier. Approximate box\ndecompositions are also supported using the algorithm from ",(0,o.jsx)(t.sup,{children:(0,o.jsx)(t.a,{href:"#user-content-fn-couckuyt2012",id:"user-content-fnref-couckuyt2012","data-footnote-ref":"","aria-describedby":"footnote-label",children:"6"})}),". See\nAppendix F.4 in ",(0,o.jsx)(t.sup,{children:(0,o.jsx)(t.a,{href:"#user-content-fn-qehvi",id:"user-content-fnref-qehvi-5","data-footnote-ref":"","aria-describedby":"footnote-label",children:"3"})})," for an analysis of approximate vs exact box\ndecompositions with EHVI. These box decompositions (approximate or exact) can\nalso be used to efficiently compute hypervolumes."]}),"\n",(0,o.jsxs)(t.p,{children:["Additionally, variations on ParEGO can be trivially implemented using an\naugmented Chebyshev scalarization as the objective with an EI-type\nsingle-objective acquisition function such as\n",(0,o.jsx)(t.a,{href:"../api/acquisition.html#botorch.acquisition.logei.qLogNoisyExpectedImprovement",children:(0,o.jsx)(t.code,{children:"qLogNoisyExpectedImprovement"})}),".\nThe\n",(0,o.jsx)(t.a,{href:"../api/utils.html#botorch.utils.multi_objective.scalarization.get_chebyshev_scalarization",children:(0,o.jsx)(t.code,{children:"get_chebyshev_scalarization"})}),"\nconvenience function generates these scalarizations."]}),"\n","\n",(0,o.jsxs)(t.section,{"data-footnotes":"",className:"footnotes",children:[(0,o.jsx)(t.h2,{className:"sr-only",id:"footnote-label",children:"Footnotes"}),"\n",(0,o.jsxs)(t.ol,{children:["\n",(0,o.jsxs)(t.li,{id:"user-content-fn-qnehvi",children:["\n",(0,o.jsxs)(t.p,{children:["S. Daulton, M. Balandat, and E. Bakshy. Parallel Bayesian Optimization of\nMultiple Noisy Objectives with Expected Hypervolume Improvement. Advances in\nNeural Information Processing Systems 34, 2021.\n",(0,o.jsx)(t.a,{href:"https://arxiv.org/abs/2105.08195",children:"paper"})," ",(0,o.jsx)(t.a,{href:"#user-content-fnref-qnehvi","data-footnote-backref":"","aria-label":"Back to reference 1",className:"data-footnote-backref",children:"\u21a9"})," ",(0,o.jsxs)(t.a,{href:"#user-content-fnref-qnehvi-2","data-footnote-backref":"","aria-label":"Back to reference 1-2",className:"data-footnote-backref",children:["\u21a9",(0,o.jsx)(t.sup,{children:"2"})]})," ",(0,o.jsxs)(t.a,{href:"#user-content-fnref-qnehvi-3","data-footnote-backref":"","aria-label":"Back to reference 1-3",className:"data-footnote-backref",children:["\u21a9",(0,o.jsx)(t.sup,{children:"3"})]})]}),"\n"]}),"\n",(0,o.jsxs)(t.li,{id:"user-content-fn-logei",children:["\n",(0,o.jsxs)(t.p,{children:["S. Ament, S. Daulton, D. Eriksson, M. Balandat, and E. Bakshy. Unexpected\nImprovements to Expected Improvement for Bayesian Optimization. Advances in\nNeural Information Processing Systems 36, 2023.\n",(0,o.jsx)(t.a,{href:"https://arxiv.org/abs/2310.20708",children:"paper"}),' "Log" variances of acquisition\nfunctions, such as\n',(0,o.jsx)(t.a,{href:"../api/acquisition.html#botorch.acquisition.multi_objective.logei.qLogNoisyExpectedHypervolumeImprovement",children:(0,o.jsx)(t.code,{children:"qLogNoisyExpectedHypervolumeImprovement"})}),",\noffer improved numerics compared to older counterparts such as\n",(0,o.jsx)(t.a,{href:"../api/acquisition.html#botorch.acquisition.multi_objective.monte_carlo.qNoisyExpectedHypervolumeImprovement",children:(0,o.jsx)(t.code,{children:"qNoisyExpectedHypervolumeImprovement"})}),". ",(0,o.jsx)(t.a,{href:"#user-content-fnref-logei","data-footnote-backref":"","aria-label":"Back to reference 2",className:"data-footnote-backref",children:"\u21a9"})]}),"\n"]}),"\n",(0,o.jsxs)(t.li,{id:"user-content-fn-qehvi",children:["\n",(0,o.jsxs)(t.p,{children:["S. Daulton, M. Balandat, and E. Bakshy. Differentiable Expected Hypervolume\nImprovement for Parallel Multi-Objective Bayesian Optimization. Advances in\nNeural Information Processing Systems 33, 2020.\n",(0,o.jsx)(t.a,{href:"https://arxiv.org/abs/2006.05078",children:"paper"})," ",(0,o.jsx)(t.a,{href:"#user-content-fnref-qehvi","data-footnote-backref":"","aria-label":"Back to reference 3",className:"data-footnote-backref",children:"\u21a9"})," ",(0,o.jsxs)(t.a,{href:"#user-content-fnref-qehvi-2","data-footnote-backref":"","aria-label":"Back to reference 3-2",className:"data-footnote-backref",children:["\u21a9",(0,o.jsx)(t.sup,{children:"2"})]})," ",(0,o.jsxs)(t.a,{href:"#user-content-fnref-qehvi-3","data-footnote-backref":"","aria-label":"Back to reference 3-3",className:"data-footnote-backref",children:["\u21a9",(0,o.jsx)(t.sup,{children:"3"})]})," ",(0,o.jsxs)(t.a,{href:"#user-content-fnref-qehvi-4","data-footnote-backref":"","aria-label":"Back to reference 3-4",className:"data-footnote-backref",children:["\u21a9",(0,o.jsx)(t.sup,{children:"4"})]})," ",(0,o.jsxs)(t.a,{href:"#user-content-fnref-qehvi-5","data-footnote-backref":"","aria-label":"Back to reference 3-5",className:"data-footnote-backref",children:["\u21a9",(0,o.jsx)(t.sup,{children:"5"})]})]}),"\n"]}),"\n",(0,o.jsxs)(t.li,{id:"user-content-fn-botorch",children:["\n",(0,o.jsxs)(t.p,{children:["M. Balandat, B. Karrer, D. R. Jiang, S. Daulton, B. Letham, A. G. Wilson,\nand E. Bakshy. BoTorch: A Framework for Efficient Monte-Carlo Bayesian\nOptimization. Advances in Neural Information Processing Systems 33, 2020.\n",(0,o.jsx)(t.a,{href:"https://arxiv.org/abs/1910.06403",children:"paper"})," ",(0,o.jsx)(t.a,{href:"#user-content-fnref-botorch","data-footnote-backref":"","aria-label":"Back to reference 4",className:"data-footnote-backref",children:"\u21a9"})]}),"\n"]}),"\n",(0,o.jsxs)(t.li,{id:"user-content-fn-yang2019",children:["\n",(0,o.jsxs)(t.p,{children:["K. Yang, M. Emmerich, A. Deutz, et al. Efficient computation of expected\nhypervolume improvement using box decomposition algorithms. J Glob Optim\n75, 2019. ",(0,o.jsx)(t.a,{href:"https://arxiv.org/abs/1904.12672",children:"paper"})," ",(0,o.jsx)(t.a,{href:"#user-content-fnref-yang2019","data-footnote-backref":"","aria-label":"Back to reference 5",className:"data-footnote-backref",children:"\u21a9"})]}),"\n"]}),"\n",(0,o.jsxs)(t.li,{id:"user-content-fn-couckuyt2012",children:["\n",(0,o.jsxs)(t.p,{children:["I. Couckuyt, D. Deschrijver and T. Dhaene. Towards Efficient Multiobjective\nOptimization: Multiobjective statistical criterions. IEEE Congress on\nEvolutionary Computation, Brisbane, QLD, 2012.\n",(0,o.jsx)(t.a,{href:"https://ieeexplore.ieee.org/document/6256586",children:"paper"})," ",(0,o.jsx)(t.a,{href:"#user-content-fnref-couckuyt2012","data-footnote-backref":"","aria-label":"Back to reference 6",className:"data-footnote-backref",children:"\u21a9"})]}),"\n"]}),"\n"]}),"\n"]})]})}function f(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>s});var i=n(6540);const o={},a=i.createContext(o);function r(e){const t=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),i.createElement(a.Provider,{value:t},e.children)}}}]);